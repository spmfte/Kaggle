{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# RNA Reactivity Prediction","metadata":{"_uuid":"c3f44d09-6acd-48cb-ab88-b63d5ff85c08","_cell_guid":"2ccba400-174f-4867-905d-62c0c16658ec","trusted":true}},{"cell_type":"markdown","source":"## 1. Importing Necessary Libraries","metadata":{"_uuid":"4c672124-674d-43ab-8be7-95b1390d457f","_cell_guid":"f7084d89-f034-413f-9c4a-9856d2cd8848","trusted":true}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder, MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, LSTM, Embedding, Dropout, Bidirectional\nfrom keras.optimizers import Adam\n\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"_uuid":"614f8844-d39d-4bf8-add5-49359a727425","_cell_guid":"05589905-1fb1-475c-8567-cd6f64c7a0c3","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-14T06:55:08.306835Z","iopub.execute_input":"2023-09-14T06:55:08.307289Z","iopub.status.idle":"2023-09-14T06:55:08.315646Z","shell.execute_reply.started":"2023-09-14T06:55:08.307252Z","shell.execute_reply":"2023-09-14T06:55:08.314047Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 2. Data Loading and Preliminary Exploration","metadata":{"_uuid":"f3e882d8-511d-4342-a78c-7b11b9bf722f","_cell_guid":"cad40226-63a7-4d3c-b53c-36402e6a9201","trusted":true}},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/stanford-ribonanza-rna-folding/train_data.csv')","metadata":{"_uuid":"5efdd510-8922-4ddf-9e67-82451f04e63e","_cell_guid":"23132663-0ff2-47f4-a438-4e089a5b892a","collapsed":false,"jupyter":{"outputs_hidden":false},"execution":{"iopub.status.busy":"2023-09-14T06:55:08.318073Z","iopub.execute_input":"2023-09-14T06:55:08.318624Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 3. Data Preprocessing","metadata":{"_uuid":"48cfab55-11e3-4d0b-900a-1ca6b4080a62","_cell_guid":"3a2e47d8-7f2c-475b-952c-e4f3f4741be7","trusted":true}},{"cell_type":"code","source":"# Finding max length of sequence for padding\nmax_sequence_length = data['sequence'].apply(len).max()\n\n# Padding the sequences with a specific character, say 'N'\ndata['padded_sequence'] = data['sequence'].apply(lambda x: x.ljust(max_sequence_length, 'N'))\n\n# Encode sequences to numerical format\nencoder = LabelEncoder()\ndata['sequence_encoded'] = data['padded_sequence'].apply(lambda x: encoder.fit_transform(list(x)))\n\n# Convert the encoded sequences to a matrix format\nX = np.array(data['sequence_encoded'].tolist())\ny = data['reactivity_0001'].values\n\n# Reshaping the input for LSTM model\nX = X.reshape(X.shape[0], X.shape[1], 1)\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)\n\n# ## 4. Deep Learning Model with LSTM","metadata":{"_uuid":"6e73aadc-2e66-447d-a503-4e75ead7c261","_cell_guid":"337f39e9-02b4-4411-a886-9ef3171f88b6","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = Sequential()\nmodel.add(Bidirectional(LSTM(128, return_sequences=True), input_shape=(X_train.shape[1], 1)))\nmodel.add(Dropout(0.5))\nmodel.add(Bidirectional(LSTM(64)))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(32, activation='relu'))\nmodel.add(Dense(1, activation='linear'))\n\noptimizer = Adam(learning_rate=0.001)\nmodel.compile(optimizer=optimizer, loss='mean_absolute_error')\nmodel.summary()\n\nhistory = model.fit(X_train, y_train, epochs=10, batch_size=128, validation_data=(X_val, y_val), verbose=1)","metadata":{"_uuid":"a759a30f-7595-4b32-a70c-775abaf202cb","_cell_guid":"5c429dcd-8a88-489d-b332-deddeaad16ad","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 5. Model Evaluation","metadata":{"_uuid":"53d65935-79a6-42ec-844f-ab6ed0e2a26e","_cell_guid":"98425d03-5628-4a13-96dc-248cd04cebcb","trusted":true}},{"cell_type":"code","source":"y_pred = model.predict(X_val)\nmae = mean_absolute_error(y_val, y_pred)\nprint(f'Mean Absolute Error on the validation set: {mae:.4f}')","metadata":{"_uuid":"58cbb47a-6408-4902-a8dc-5027e9afc5b5","_cell_guid":"ed7a8f5f-f2fe-435c-82c1-4cbe896d0e98","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## 6. Visualizing Loss","metadata":{"_uuid":"f9317c1f-5c80-4e1c-81a8-d2386a0a758f","_cell_guid":"bab62cb4-630b-4bea-bec4-bbf080fbe0e6","trusted":true}},{"cell_type":"code","source":"plt.figure(figsize=(12,6))\nplt.plot(history.history['loss'], label='Training Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training and Validation Loss over Epochs')\nplt.show()","metadata":{"_uuid":"30a6d5e4-9585-4d69-8dd2-b06093af125f","_cell_guid":"d59905a6-0b7e-479d-9ac9-cf2b675ed951","collapsed":false,"jupyter":{"outputs_hidden":false},"trusted":true},"execution_count":null,"outputs":[]}],"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}}